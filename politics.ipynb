{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f65127b129b41c3adc7819827b30b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f0cb17fcabc414086ad0bef56cc792c",
              "IPY_MODEL_37a8b48d5f8c4ceebd36c9d69ac715b1",
              "IPY_MODEL_e6bd25a8be6f4df7a341df30ff4c8547"
            ],
            "layout": "IPY_MODEL_d0ab8dd6e2214af0a49c75eb547b55da"
          }
        },
        "2f0cb17fcabc414086ad0bef56cc792c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8a2028629ed4832a0f96c5aaf462064",
            "placeholder": "​",
            "style": "IPY_MODEL_643473197fdb4960b889cc424925a556",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "37a8b48d5f8c4ceebd36c9d69ac715b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d3c1cd64f849d9aa6e8fb1d5255343",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1996b093b79543f390186182301195cc",
            "value": 714290682
          }
        },
        "e6bd25a8be6f4df7a341df30ff4c8547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_684b555f4be44308b12722d2e28cd0df",
            "placeholder": "​",
            "style": "IPY_MODEL_ba370b5accdb411a818025aab8001fc5",
            "value": " 714M/714M [00:11&lt;00:00, 94.4MB/s]"
          }
        },
        "d0ab8dd6e2214af0a49c75eb547b55da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8a2028629ed4832a0f96c5aaf462064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "643473197fdb4960b889cc424925a556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74d3c1cd64f849d9aa6e8fb1d5255343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1996b093b79543f390186182301195cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "684b555f4be44308b12722d2e28cd0df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba370b5accdb411a818025aab8001fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#install\n",
        "!pip install keras\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKxTygA9dCxY",
        "outputId": "53a4691e-c49c-47b9-f5d6-0e1b7b99e21f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.utils import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime"
      ],
      "metadata": {
        "id": "toHCsxYobKdA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# year 마다 데이터 불러와서 변수 생성\n",
        "\n",
        "# year_list = ['15','16','17','18','19','20']\n",
        "# for year in year_list:\n",
        "#   globals()[f'data_{year}'] = pd.read_csv(f'/content/drive/MyDrive/politics_data/{year}대 민주당_보수당 구분.csv')\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/politics_data/15대 민주당_보수당 구분.csv')"
      ],
      "metadata": {
        "id": "m3wAvORsW68G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15대 먼저 돌려보자"
      ],
      "metadata": {
        "id": "2RASuszWXaJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "LfEv-_rPYPyJ",
        "outputId": "bcd641ca-6738-4bc9-e171-f5886d7a2fcd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   L|R                                            Content\n",
              "0    1  의석을 정돈해 주시기 바랍니다. 성원이 되었으므로 제5차 2002년월드컵등국제경기대...\n",
              "1    1  의사일정에 들어가기 전에 위원장의 신상에 관한 발언을 하고자 합니다. 존경하는 위원...\n",
              "2    1  신한국당에서 간사직을 맡고 있는 김기수 위원입니다. 조금 전에 위원장께서 말씀을 드...\n",
              "3    1  그러면 의사일정 제1항 위원장(신경식) 사임의 건을 상정하겠습니다. 신경식 위원장님...\n",
              "4    1  다음은 의사일정 제2항 위원장 선임의 건을 상정하겠습니다. 위원 여러분께서 잘 아시...\n",
              "5    0  새정치국민회의 소속 박광태 위원입니다. 위원장 선임방법은 사회자께서도 말씀하셨다시피...\n",
              "6    1  지금 존경하는 박광태 위원께서 위원장 선임방법에 대하여 구두호천에 의해서 선출하자는...\n",
              "7    0  새정치국민회의 최재승 위원입니다. 우리 위원회는 본래 설치한 목적이 한국적인 국제경...\n",
              "8    1  방금 최재승 위원으로부터 김진재 위원을 위원장으로 선임하자는 추천이 있었습니다. 다...\n",
              "9    1  먼저 여러 가지로 부족한 점이 많은 이 사람을 만장일치로 위원장으로 선출해 주신 선..."
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-6915a018-d215-4787-b4e8-2ead7c553252\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>L|R</th>\n",
              "      <th>Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>의석을 정돈해 주시기 바랍니다. 성원이 되었으므로 제5차 2002년월드컵등국제경기대...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>의사일정에 들어가기 전에 위원장의 신상에 관한 발언을 하고자 합니다. 존경하는 위원...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>신한국당에서 간사직을 맡고 있는 김기수 위원입니다. 조금 전에 위원장께서 말씀을 드...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>그러면 의사일정 제1항 위원장(신경식) 사임의 건을 상정하겠습니다. 신경식 위원장님...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>다음은 의사일정 제2항 위원장 선임의 건을 상정하겠습니다. 위원 여러분께서 잘 아시...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>새정치국민회의 소속 박광태 위원입니다. 위원장 선임방법은 사회자께서도 말씀하셨다시피...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>지금 존경하는 박광태 위원께서 위원장 선임방법에 대하여 구두호천에 의해서 선출하자는...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>새정치국민회의 최재승 위원입니다. 우리 위원회는 본래 설치한 목적이 한국적인 국제경...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>방금 최재승 위원으로부터 김진재 위원을 위원장으로 선임하자는 추천이 있었습니다. 다...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>먼저 여러 가지로 부족한 점이 많은 이 사람을 만장일치로 위원장으로 선출해 주신 선...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6915a018-d215-4787-b4e8-2ead7c553252')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e3d7f1e1-b1b9-4933-8923-74eb551a9fd8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3d7f1e1-b1b9-4933-8923-74eb551a9fd8')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e3d7f1e1-b1b9-4933-8923-74eb551a9fd8 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6915a018-d215-4787-b4e8-2ead7c553252 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6915a018-d215-4787-b4e8-2ead7c553252');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAVpIv-Qz2Os",
        "outputId": "eba11d57-226d-4a60-8c21-38c22e922e47"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['L|R', 'Content'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gpu (cuda)\n",
        "if torch.cuda.is_available():\n",
        "  DEVICE = torch.device(\"cuda\")\n",
        "else:\n",
        "  DEVICE= torch.device(\"cpu\")\n",
        "\n",
        "print(DEVICE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcBottcIYNO3",
        "outputId": "31fa65d8-f0fc-4b27-d5cb-cdb25e95bc0f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA & 전처리\n"
      ],
      "metadata": {
        "id": "Fp_y02yieHS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxsKxRUfcB-A",
        "outputId": "f852d0ac-ed7e-4339-d8bc-6ce55c367ba9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "L|R        0\n",
              "Content    1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[data['Content'].isnull()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "ftvTojGid_um",
        "outputId": "00d195f2-b2df-43bf-bcad-feb87ff5e359"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        L|R Content\n",
              "221670    1     NaN"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-0c2a4003-1f25-4565-9b3e-4667f8467adc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>L|R</th>\n",
              "      <th>Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>221670</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c2a4003-1f25-4565-9b3e-4667f8467adc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-47e740f1-0232-437a-bea9-abc5c146e140\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47e740f1-0232-437a-bea9-abc5c146e140')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-47e740f1-0232-437a-bea9-abc5c146e140 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c2a4003-1f25-4565-9b3e-4667f8467adc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c2a4003-1f25-4565-9b3e-4667f8467adc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 삭제\n",
        "data.dropna(axis=0,how='any',inplace=True)\n",
        "\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x80-eRPseRYS",
        "outputId": "db0b4c94-25b9-4118-c310-7272e5ae7fd0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "L|R        0\n",
              "Content    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 칼럼명 & 순서 변경\n",
        "data.columns = ['label','content']\n",
        "data = data[['content','label']]\n",
        "\n"
      ],
      "metadata": {
        "id": "mN_UkL4dedCX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label 비율 확인\n",
        "data['label'].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNgNe_3Cet2w",
        "outputId": "4e929c80-32fa-467c-f2f4-ca75ec712479"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.618191\n",
              "0    0.381809\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "GoslQ3Lcseuq",
        "outputId": "76e1415e-0f97-443b-9df8-3fa06800c2c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             content  label\n",
              "0  의석을 정돈해 주시기 바랍니다. 성원이 되었으므로 제5차 2002년월드컵등국제경기대...      1\n",
              "1  의사일정에 들어가기 전에 위원장의 신상에 관한 발언을 하고자 합니다. 존경하는 위원...      1\n",
              "2  신한국당에서 간사직을 맡고 있는 김기수 위원입니다. 조금 전에 위원장께서 말씀을 드...      1\n",
              "3  그러면 의사일정 제1항 위원장(신경식) 사임의 건을 상정하겠습니다. 신경식 위원장님...      1\n",
              "4  다음은 의사일정 제2항 위원장 선임의 건을 상정하겠습니다. 위원 여러분께서 잘 아시...      1\n",
              "5  새정치국민회의 소속 박광태 위원입니다. 위원장 선임방법은 사회자께서도 말씀하셨다시피...      0\n",
              "6  지금 존경하는 박광태 위원께서 위원장 선임방법에 대하여 구두호천에 의해서 선출하자는...      1\n",
              "7  새정치국민회의 최재승 위원입니다. 우리 위원회는 본래 설치한 목적이 한국적인 국제경...      0\n",
              "8  방금 최재승 위원으로부터 김진재 위원을 위원장으로 선임하자는 추천이 있었습니다. 다...      1\n",
              "9  먼저 여러 가지로 부족한 점이 많은 이 사람을 만장일치로 위원장으로 선출해 주신 선...      1"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-5ac24ced-0f22-461d-b5bf-80c7462e1338\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>의석을 정돈해 주시기 바랍니다. 성원이 되었으므로 제5차 2002년월드컵등국제경기대...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>의사일정에 들어가기 전에 위원장의 신상에 관한 발언을 하고자 합니다. 존경하는 위원...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>신한국당에서 간사직을 맡고 있는 김기수 위원입니다. 조금 전에 위원장께서 말씀을 드...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>그러면 의사일정 제1항 위원장(신경식) 사임의 건을 상정하겠습니다. 신경식 위원장님...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>다음은 의사일정 제2항 위원장 선임의 건을 상정하겠습니다. 위원 여러분께서 잘 아시...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>새정치국민회의 소속 박광태 위원입니다. 위원장 선임방법은 사회자께서도 말씀하셨다시피...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>지금 존경하는 박광태 위원께서 위원장 선임방법에 대하여 구두호천에 의해서 선출하자는...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>새정치국민회의 최재승 위원입니다. 우리 위원회는 본래 설치한 목적이 한국적인 국제경...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>방금 최재승 위원으로부터 김진재 위원을 위원장으로 선임하자는 추천이 있었습니다. 다...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>먼저 여러 가지로 부족한 점이 많은 이 사람을 만장일치로 위원장으로 선출해 주신 선...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ac24ced-0f22-461d-b5bf-80c7462e1338')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-38755be6-93cb-4d9b-b6ab-f6b3da6cacf1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38755be6-93cb-4d9b-b6ab-f6b3da6cacf1')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-38755be6-93cb-4d9b-b6ab-f6b3da6cacf1 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ac24ced-0f22-461d-b5bf-80c7462e1338 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ac24ced-0f22-461d-b5bf-80c7462e1338');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(data,test_size=0.2)\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coRYwwDCeupi",
        "outputId": "d2f1c19a-fbba-4ec8-bc5f-d5f1751febbb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(321675, 2)\n",
            "(80419, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리"
      ],
      "metadata": {
        "id": "0jP040k4l7V2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT 입력 형식에 맞게 변환\n",
        "document_bert = [\"[CLS] \" + str(s) + \" [SEP]\" for s in train.content]\n",
        "document_bert[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W053Bpxrl_Lz",
        "outputId": "70c18976-28c2-42ee-dc36-3ae41dc8c090"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 그것이 몇 조냐 말이에요. 아는 사람 없어요? [SEP]',\n",
              " '[CLS] 지금 이해구 위원께서 외형적으로 좋게 말씀하셨는데 사실상 준설때문에 일어나는 농조 안의 비리가 엄청나게 있는 것으로 파악하고 있습니다. 지금 농조에 대한 감독권이 1차적으로 시도에 있고 농림수산부에서 직접 하는 것입니까? 문제점이 있으면 누가 감사하고 누가 지적하고 그럽니까? [SEP]',\n",
              " '[CLS] 알겠습니다. [SEP]',\n",
              " '[CLS] 의사일정에 들어가기 전에 지금 입법조사관이 보고하신 대로 존경하는 이우재 위원께서 우리 위원회에 보임되어 오셨습니다. 인사 말씀해 주시기 바랍니다. [SEP]',\n",
              " '[CLS] 지금 얘기가 직접 나왔으니까 지금 그런 것 기아의 퇴출 부도처리 또 제일은행 같은 것 이것을 현실적으로 그렇게 할 수 없었다 하는 것은 증인의 판단입니까? 아니면…… [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이징\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "tokenized_texts = [tokenizer.tokenize(s) for s in document_bert]\n"
      ],
      "metadata": {
        "id": "JIt9MCY2q7Y2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(document_bert[0])\n",
        "print(tokenized_texts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXwJMdzc8K3B",
        "outputId": "cf885040-a05d-44f5-a4d7-61887e20ca3c"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] 채 위원! 종합적으로 왜 손을 대지 못하는 상황에 있었는가 그것을 설명하니까 그 설명을 다 들으시고 질의해 주세요. 계속 답변해 주세요. [SEP]\n",
            "['[CLS]', '채', '위', '##원', '!', '종', '##합', '##적으로', '왜', '손', '##을', '대', '##지', '못', '##하는', '상', '##황', '##에', '있', '##었', '##는', '##가', '그', '##것을', '설', '##명', '##하', '##니', '##까', '그', '설', '##명을', '다', '들', '##으', '##시', '##고', '질', '##의', '##해', '주', '##세', '##요', '.', '계속', '답', '##변', '##해', '주', '##세', '##요', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨 추출\n",
        "labels = train['label'].values\n",
        "labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh61xmSZrNMl",
        "outputId": "4a05825e-f1b3-4d65-c010-6bbd726511bb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#패딩\n",
        "\n",
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "MAX_LEN = 128\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1fBbHzL8Vix",
        "outputId": "6f4d6536-dd51-426c-81c8-311ad40f91c7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   101,   8924,  97403,   9282,   9678, 118728,   9251,  10739,\n",
              "        10530,  48549,    119,   9519,  11018,   9405,  61250,   9555,\n",
              "        12965,  48549,    136,    102,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 어텐션 마스크 초기화\n",
        "attention_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwRflNwf8wac",
        "outputId": "94283397-72b9-4fcf-d754-f77b46d07e73"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련셋과 검증셋으로 분리\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n",
        "                                                                                    labels,\n",
        "                                                                                    random_state=2018,\n",
        "                                                                                    test_size=0.1)\n",
        "\n",
        "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks,\n",
        "                                                       input_ids,\n",
        "                                                       random_state=2018,\n",
        "                                                       test_size=0.1)\n",
        "\n",
        "# 데이터를 파이토치의 텐서로 변환\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "print(train_inputs[0])\n",
        "print(train_labels[0])\n",
        "print(train_masks[0])\n",
        "print(validation_inputs[0])\n",
        "print(validation_labels[0])\n",
        "print(validation_masks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwzbmAlF9A_Q",
        "outputId": "4ebc5000-2973-44a9-e8b3-eb31115dc795"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   101,   9663,  11018,   8924,  93834,   9251,  12178,   8869,  48345,\n",
            "           119,   9485,  25549,  21611, 103155,  44359,  19105,   8887, 103155,\n",
            "         10622,  12308,  10954,  16367,  42784,  10530,   9323,  37824,  11513,\n",
            "          9965,  12965,  48549,    119,   8924,  37388, 118748,  11664,  25805,\n",
            "         17206, 105946,   9764,  22200,  17022,  86015,  18392,  93835,  12749,\n",
            "         18392,  11261,   9612,  14871,  85386,   8852,  11664,   9186,  48653,\n",
            "          9460,  19105,  12428,  21789,  11489,  10348,  21789,   9186,  48653,\n",
            "         11261,   9692, 119147,  41521,  90537,  48549,    119,   8924,  30873,\n",
            "         25503, 118671,   8924,  82838,   9251, 119106,  10622,   9460,  16605,\n",
            "         70146,   9960,  87281,  25503, 118671,   9685, 119081,  48345,    119,\n",
            "          9546, 118837,  90537,   9246,  16323,  25258,   9574,  79544,  10739,\n",
            "         24335,  60362,  27487,   9706,  40032,   9998,  13890, 108578,   9251,\n",
            "        119106, 102246,  12092,   8924,  56710,  67288,  15387,   9934,  30842,\n",
            "         10892,   9555,  28578,   9672,  11287,   9519,  11018,   8870,  12453,\n",
            "          9069,  18778])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "tensor([   101,   8924, 118871,  12508,  48549,    136,    102,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 배치 사이즈\n",
        "batch_size = 32\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "m2LWWcbH_5Xs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리 test (train 과 동일)\n"
      ],
      "metadata": {
        "id": "S6-Eyz5N_-zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 리뷰 문장 추출\n",
        "sentences = test['content']\n",
        "sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skTvjM2pABJf",
        "outputId": "d7c37947-f697-44f6-82a5-4f3c6ce8d297"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "303436    금강산 관광객 민영미 씨 억류사건은 우리에게 상당한 충격을 주고 있습니다. 햇볕정책...\n",
              "252073    그러면 지금 솔담배가 시골에 가면 나오는 날은 대판 싸움이 납니다. 서로 그 담배 ...\n",
              "326585                                그것이 언제라고 말씀하실 수 있습니까?\n",
              "269804    발언을 하고 있어요. 남의 얘기를 듣지도 않고 그럽니까? 공정거래위원장이 판단해서 ...\n",
              "192844               수고하셨습니다. 다음은 존경하는 신낙균 위원 질의해 주시기 바랍니다.\n",
              "176837    그러면 이렇게 하시지요. 지금 아마 답변 내용이 조금 남아 있는지 모르겠는데 전부 ...\n",
              "137451                                      그것을 어떻게 처리했습니까?\n",
              "285569    이 문제에 대해서 이따가 박광태 위원 말씀대로 답변하시는 도중에 박광태 위원의 질의...\n",
              "73502                             제가 자료제출 요구를 한다고 말하지 않았어요?\n",
              "299110    그 한 시간이라는 것은 지금 누구한테 물어보겠다는 것입니까? 형무소장한테 물어보는 ...\n",
              "Name: content, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT의 입력 형식에 맞게 변환\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
        "sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lltA7FsRAC6L",
        "outputId": "4228a8dd-b2c7-42c3-fca8-e65836d320da"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 금강산 관광객 민영미 씨 억류사건은 우리에게 상당한 충격을 주고 있습니다. 햇볕정책 1년 4개월만에 또 하나의 시련에 부딪혔다고 봅니다. 우리가 또 이 문제해결을 위해서 최우선적으로 총력을 경주해야 한다고 봅니다. 그러나 우리가 곰곰히 따지고 보면 햇볕정책 때문에 이런 억류사건이 필연적으로 일어난 것은 아니라고 봅니다. 왜냐 하면 우리가 최근 수년 동안 북한이 이러한 억류를 한 사례를 몇 가지 본다면 구정권때인 95년 8월에도 쌀 지원을 위해서 청진항에 입항한 삼선비너스호 1등 항해사 이양천 씨가 청진항 주변 사진을 찍었다는 단순한 이유로 8일 동안이나 억류를 하고 1000달러의 벌금을 물려서 석방을 했습니다. 또 97년 10월 이것도 역시 김영삼 정권때 일입니다마는 김정일 위원장의 사진이 실린 로동신문을 찢어서 휴지통에 넣었다는 이유로 경수로 공사현장의 근로자들을 그 당시 집단적으로 숙소에 5일간이나 감금을 했다가 우리가 재발방지를 다짐하고 항의를 하니까 석방시킨 사례도 있었습니다. 또 세번째로는 94년 8월에 북한의 중국 국경지역인 훈춘지역 교포 상대로 의류장사를 하던 중국동포 배용문 이상찬 씨를 북한측에서 20일간이나 함북 온성에 억류시켰다가 석방시킨 사건도 있었습니다. 또 최근에는 미국 시민권자인 김진경 연변 과기대 총장을 기독교 전파 등의 이유로 43일간이나 억류시켰던 일이 있었습니다. 그래서 햇볕정책 1년 4개월의 필연적인 부산물로서 이런 억류사건이 일어났다고는 보지 않습니다. 그러나 어떻든 정부가 대북 포용정책을 취하는 과정에서 더구나 금강산 관광중에서 일어난 일이기 때문에 우리 정부에서는 최우선적으로 이 문제 해결을 위해서 총력을 경주해야 하는데 오늘 보고된 내용은 너무 현대측에 실질적으로 모든 것을 일임하고 있지 않느냐 하는 인상을 지울 수 없는데 좀더 총체적이고 강력한 석방대책을 세워서 추진해야 된다고 보는데 장관께서는 어떻게 생각하십니까? 간략하게 답변 주시지요. [SEP]',\n",
              " '[CLS] 그러면 지금 솔담배가 시골에 가면 나오는 날은 대판 싸움이 납니다. 서로 그 담배 더 가져가려고. 이런 국민의 기호품인데 소시민이 피는 솔담배는 양을 줄이는지? 솔담배 이것은 대통령공약사업이에요. 94년 95년 96년 솔담배 생산량을 비교해주시고 또 하나는 담배가 시장에 다녀보면 전부 호주머니에 외국산담배만 더 많은 것 같습니다. 그래서 이 점유율 94년 95년 96년 어떻게 변경되어 왔는지 프로테이지를 주시고요. 하나 중요한 것을 말씀드려야겠는데 인삼분야는 이제는 농림수산부로 넘어가지 않습니까. 그간 인삼공사에서 홍삼이다 백삼이다 해서 쭉 잘해오셨는데 인삼공사안에 있는 인삼재고량을 정말 거짓말 하면 안됩니다. 제품재고량 폐품재고량 수치상 재고량 이것이 엄청납니다. 제가 고향이 논산이라 인삼 기르는 사람들을 통해서 인삼창에 사람들 들여보내 보았어요. 엄청난데 이것을 공식적으로 얘기를 안해요. 대충대충 얘기하고 넘어가는대 이제는 자산정리가 되어야 할 것인데 정확한 재고량을 오픈하셔서 농림수산부에 넘기면서 자산을 따질 적에 이것도 계산해야 됩니다. 곧 민영화한다고 하는데 이 때도 이것은 자산 계산해야 합니다. 이것 이번에 김 사장께서 하셨다가 다음 민영화할 때 재고량이 더 나온다든지 하면 위증한 것으로 나는 정말 고발할 겁니다. 이 다음에 사장을 그만 두시고라도 고향을 찾아가서라도 고발하겠습니다. 그러니까 정확한 것을 알려주세요. 그리고 인삼농가에다가 1100억을 지원했는데 지금 그것 때문에 인삼경작자들이 난리가 났어요. 농림수산부로 이관되면 인삼공사에서는 그 돈을 내놓으라고 할 것 아니냐 그러니까 또 인삼에 관계된 단체들은 서로 자기네 앞으로 그 자금을 명칭만 바꾸어서 이월해 달라 이런 사람들도 있고 그러면 인삼공사에서는 그 돈을 도로 내놓아라 그럴 것 아니겠습니까? 그래서 이것을 어떻게 하는 것이 인삼 경작자들한테 손실을 안 끼칠지 그 대안을 하나 만들어서 주세요. 그리고 제가 14대 때도 얘기를 했는데 인삼이나 담배는 순수한 우리 농민이 길러서 만든 것입니다. 정말 신토불이예요. 그런데 거기에 관리면에서 쌓이는 자금은 외국계 은행에 예금을 많이 해놓았어요. 지금도 그것이 있는지 지난번에 제가 14대 때 발언을 해가지고 외국계 은행 한미은행을 다 뽑은 적이 있어요. 왜 우리 돈을 그런 데다 예금하느냐 이것입니다. 다른 우리 시중은행에다 넣어 달라 이것이에요. 그래서 담배인삼공사에 있는 돈의 흐름의 은행에 예치된 은행들 리스트를 하나 자료로 내주시기 바랍니다. [SEP]',\n",
              " '[CLS] 그것이 언제라고 말씀하실 수 있습니까? [SEP]',\n",
              " '[CLS] 발언을 하고 있어요. 남의 얘기를 듣지도 않고 그럽니까? 공정거래위원장이 판단해서 답변할 문제이고 그 판단이 옳으냐 그르냐 하는 것은 위원회에서 또 우리대로 판단을 해야 할 문제다. 다만 비밀을 보호하기 위해서 국회에서 국정감사 자료를 내놓는 것이 상대문건이 비밀로 구분이 안 되어 있는데 비밀을 보호하기 위해서 한다는 것은 온당한 답변은 못 된다 저는 이렇게 생각을 합니다. 그 대신 80여 개 기업에 대해서 이 잡듯 조사한 문건이 한 트럭은 될 텐데 그것을 공개하라 하는 것으로 오인을 하지 않았느냐 그렇기 때문에 5대 기업의 내부거래에 대해 조사한 요약을 보내고 또 기업들이 이의신청한 요약을 보내고 하는 것으로 우리가 요구하는 자료로 집약하고 그 내용에 대해서는 국감 때 얼마든지 조사할 수 있는 것 아니냐 그 자료의 분량과 범위를 지금 양해해서 내달라 하는 것으로 정리를…… [SEP]',\n",
              " '[CLS] 수고하셨습니다. 다음은 존경하는 신낙균 위원 질의해 주시기 바랍니다. [SEP]',\n",
              " '[CLS] 그러면 이렇게 하시지요. 지금 아마 답변 내용이 조금 남아 있는지 모르겠는데 전부 서면으로 같이 답변해 주시고 그 서면답변 내용을 조금 전에 서면으로 질의한 부분이 있는데 그 서면질의에 대한 답변을 하실 때 같이 답변을 해 주시기 바랍니다. 수고하셨습니다. 이 정도로 감사를 모두 마치고자 합니다. 오늘 성실하게 감사에 임해 주신 광주고등검찰청검사장님과 광주지방검찰청검사장님을 비롯한 관계관 여러분들의 노고에 대해서 감사를 드립니다. 오늘 이 자리에서 여러 감사위원들이 지적한 사항은 평소 검찰을 사랑하고 또 검찰의 발전을 위한 충정에서 나온 말씀이라고 이해하시고 앞으로 검찰의 업무수행에 많이 참고하시고 그러한 지적 사항이 재발되지 않도록 각별히 노력해 주실 것을 부탁을 드립니다. 이상으로 1998년도 광주고등검찰청 광주지방검찰청에 대한 국정감사를 모두 마치겠습니다.(18시07분 감사종료) [SEP]',\n",
              " '[CLS] 그것을 어떻게 처리했습니까? [SEP]',\n",
              " '[CLS] 이 문제에 대해서 이따가 박광태 위원 말씀대로 답변하시는 도중에 박광태 위원의 질의라고 생각하셔도 좋습니다마는 다시 한번 종합적으로 보고를 해주십시오. [SEP]',\n",
              " '[CLS] 제가 자료제출 요구를 한다고 말하지 않았어요? [SEP]',\n",
              " '[CLS] 그 한 시간이라는 것은 지금 누구한테 물어보겠다는 것입니까? 형무소장한테 물어보는 것입니까 경찰서장한테 물어보겠다는 거예요? [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨 추출\n",
        "labels = test['label'].values\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKnUlY84ADxj",
        "outputId": "2313631d-a8c6-4a6b-a8f3-39bbaaaf138d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H83SgWi3AEkK",
        "outputId": "2a3d9dd0-aa54-4415-b371-c317ab493eac"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] 금강산 관광객 민영미 씨 억류사건은 우리에게 상당한 충격을 주고 있습니다. 햇볕정책 1년 4개월만에 또 하나의 시련에 부딪혔다고 봅니다. 우리가 또 이 문제해결을 위해서 최우선적으로 총력을 경주해야 한다고 봅니다. 그러나 우리가 곰곰히 따지고 보면 햇볕정책 때문에 이런 억류사건이 필연적으로 일어난 것은 아니라고 봅니다. 왜냐 하면 우리가 최근 수년 동안 북한이 이러한 억류를 한 사례를 몇 가지 본다면 구정권때인 95년 8월에도 쌀 지원을 위해서 청진항에 입항한 삼선비너스호 1등 항해사 이양천 씨가 청진항 주변 사진을 찍었다는 단순한 이유로 8일 동안이나 억류를 하고 1000달러의 벌금을 물려서 석방을 했습니다. 또 97년 10월 이것도 역시 김영삼 정권때 일입니다마는 김정일 위원장의 사진이 실린 로동신문을 찢어서 휴지통에 넣었다는 이유로 경수로 공사현장의 근로자들을 그 당시 집단적으로 숙소에 5일간이나 감금을 했다가 우리가 재발방지를 다짐하고 항의를 하니까 석방시킨 사례도 있었습니다. 또 세번째로는 94년 8월에 북한의 중국 국경지역인 훈춘지역 교포 상대로 의류장사를 하던 중국동포 배용문 이상찬 씨를 북한측에서 20일간이나 함북 온성에 억류시켰다가 석방시킨 사건도 있었습니다. 또 최근에는 미국 시민권자인 김진경 연변 과기대 총장을 기독교 전파 등의 이유로 43일간이나 억류시켰던 일이 있었습니다. 그래서 햇볕정책 1년 4개월의 필연적인 부산물로서 이런 억류사건이 일어났다고는 보지 않습니다. 그러나 어떻든 정부가 대북 포용정책을 취하는 과정에서 더구나 금강산 관광중에서 일어난 일이기 때문에 우리 정부에서는 최우선적으로 이 문제 해결을 위해서 총력을 경주해야 하는데 오늘 보고된 내용은 너무 현대측에 실질적으로 모든 것을 일임하고 있지 않느냐 하는 인상을 지울 수 없는데 좀더 총체적이고 강력한 석방대책을 세워서 추진해야 된다고 보는데 장관께서는 어떻게 생각하십니까? 간략하게 답변 주시지요. [SEP]\n",
            "['[CLS]', '금', '##강', '##산', '관', '##광', '##객', '민', '##영', '##미', '씨', '억', '##류', '##사', '##건', '##은', '우', '##리에', '##게', '상', '##당한', '충', '##격을', '주', '##고', '있', '##습', '##니다', '.', '[UNK]', '1', '##년', '4', '##개', '##월', '##만', '##에', '또', '하나의', '시', '##련', '##에', '부', '##딪', '##혔', '##다고', '[UNK]', '.', '우', '##리가', '또', '이', '문', '##제', '##해', '##결', '##을', '위해', '##서', '최', '##우', '##선', '##적으로', '총', '##력을', '경', '##주', '##해야', '한다', '##고', '[UNK]', '.', '그러나', '우', '##리가', '곰', '##곰', '##히', '따', '##지고', '보', '##면', '[UNK]', '때문에', '이런', '억', '##류', '##사', '##건', '##이', '필', '##연', '##적으로', '일', '##어난', '것은', '아니라', '##고', '[UNK]', '.', '왜', '##냐', '하', '##면', '우', '##리가', '최', '##근', '수', '##년', '동안', '북', '##한', '##이', '이러한', '억', '##류', '##를', '한', '사', '##례', '##를', '몇', '가지', '본', '##다', '##면', '구', '##정', '##권', '##때', '##인', '95', '##년', '8월', '##에도', '쌀', '지', '##원을', '위해', '##서', '청', '##진', '##항', '##에', '입', '##항', '##한', '삼', '##선', '##비', '##너', '##스', '##호', '1', '##등', '항', '##해', '##사', '이', '##양', '##천', '씨', '##가', '청', '##진', '##항', '주', '##변', '사', '##진', '##을', '찍', '##었다', '##는', '단', '##순', '##한', '이유로', '8일', '동안', '##이나', '억', '##류', '##를', '하고', '1000', '##달', '##러', '##의', '벌', '##금', '##을', '물', '##려', '##서', '석', '##방', '##을', '했', '##습', '##니다', '.', '또', '97', '##년', '10월', '이', '##것', '##도', '역시', '김', '##영', '##삼', '정', '##권', '##때', '일', '##입', '##니다', '##마', '##는', '김', '##정', '##일', '위', '##원', '##장의', '사', '##진', '##이', '실', '##린', '로', '##동', '##신문', '##을', '[UNK]', '휴', '##지', '##통', '##에', '넣', '##었다', '##는', '이유로', '경', '##수로', '공', '##사', '##현', '##장의', '근', '##로', '##자', '##들을', '그', '당시', '집', '##단', '##적으로', '숙', '##소', '##에', '5일', '##간이', '##나', '감', '##금', '##을', '했다', '##가', '우', '##리가', '재', '##발', '##방', '##지를', '다', '##짐', '##하고', '항', '##의를', '하', '##니', '##까', '석', '##방', '##시', '##킨', '사', '##례', '##도', '있', '##었', '##습', '##니다', '.', '또', '세', '##번째', '##로는', '94', '##년', '8월', '##에', '북', '##한', '##의', '중국', '국', '##경', '##지', '##역', '##인', '훈', '##춘', '##지', '##역', '교', '##포', '상', '##대로', '의', '##류', '##장', '##사를', '하', '##던', '중국', '##동', '##포', '배', '##용', '##문', '이상', '##찬', '씨', '##를', '북', '##한', '##측', '##에서', '20일', '##간이', '##나', '함', '##북', '온', '##성', '##에', '억', '##류', '##시', '##켰다', '##가', '석', '##방', '##시', '##킨', '사건', '##도', '있', '##었', '##습', '##니다', '.', '또', '최', '##근', '##에는', '미국', '시', '##민', '##권', '##자인', '김', '##진', '##경', '연', '##변', '과', '##기', '##대', '총', '##장을', '기', '##독', '##교', '전', '##파', '등의', '이유로', '43', '##일', '##간이', '##나', '억', '##류', '##시', '##켰', '##던', '일', '##이', '있', '##었', '##습', '##니다', '.', '그', '##래', '##서', '[UNK]', '1', '##년', '4', '##개', '##월', '##의', '필', '##연', '##적인', '부', '##산', '##물', '##로서', '이런', '억', '##류', '##사', '##건', '##이', '일', '##어', '##났다', '##고', '##는', '보', '##지', '않', '##습', '##니다', '.', '그러나', '어', '##떻', '##든', '정', '##부가', '대', '##북', '포', '##용', '##정', '##책', '##을', '취', '##하는', '과', '##정에서', '더', '##구', '##나', '금', '##강', '##산', '관', '##광', '##중에', '##서', '일', '##어난', '일', '##이', '##기', '때문에', '우', '##리', '정', '##부에', '##서는', '최', '##우', '##선', '##적으로', '이', '문', '##제', '해', '##결', '##을', '위해', '##서', '총', '##력을', '경', '##주', '##해야', '하는', '##데', '오', '##늘', '보고', '##된', '내', '##용', '##은', '너', '##무', '현대', '##측', '##에', '실', '##질', '##적으로', '모든', '것을', '일', '##임', '##하고', '있', '##지', '않', '##느', '##냐', '하는', '인', '##상을', '지', '##울', '수', '없는', '##데', '좀', '##더', '총', '##체', '##적', '##이고', '강', '##력', '##한', '석', '##방', '##대', '##책', '##을', '세', '##워', '##서', '추', '##진', '##해야', '된다', '##고', '보', '##는데', '장', '##관', '##께', '##서는', '어', '##떻', '##게', '생', '##각', '##하', '##십', '##니', '##까', '?', '간', '##략', '##하게', '답', '##변', '주', '##시', '##지', '##요', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "MAX_LEN = 128\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsHpvDntAEvB",
        "outputId": "7fb94bb9-27da-43e4-d790-d8635298ea56"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   101,   8928,  47181,  21386,   8900, 118649, 118617,   9311,\n",
              "        30858,  22458,   9516,   9547,  46520,  12945,  71439,  10892,\n",
              "         9604,  46766,  14153,   9414, 103088,   9770,  53635,   9689,\n",
              "        11664,   9647, 119081,  48345,    119,    100,    122,  10954,\n",
              "          125,  21789,  38851,  19105,  10530,   9144,  90387,   9485,\n",
              "       101440,  10530,   9365, 118824, 119436,  85634,    100,    119,\n",
              "         9604,  44130,   9144,   9638,   9297,  17730,  14523,  74322,\n",
              "        10622,  19905,  12424,   9764,  27355,  18471,  17022,   9761,\n",
              "        33975,   8885,  16323, 108436,  16139,  11664,    100,    119,\n",
              "        21890,   9604,  44130,   8893, 118642,  18108,   9130,  68833,\n",
              "         9356,  14867,    100,  20729,  80956,   9547,  46520,  12945,\n",
              "        71439,  10739,   9949,  25486,  17022,   9641,  54305,  30050,\n",
              "        45021,  11664,    100,    119,   9596, 118728,   9952,  14867,\n",
              "         9604,  44130,   9764,  50248,   9460,  10954,  41886,   9366,\n",
              "        11102,  10739,  34079,   9547,  46520,  11513,   9954,   9405,\n",
              "        58762,  11513,   9282,  69164,   9358,  11903,  14867,   8908])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 어텐션 마스크 초기화\n",
        "attention_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8at3EA-AE5N",
        "outputId": "0c1860ab-26b3-461d-86d6-81b720955198"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 파이토치의 텐서로 변환\n",
        "test_inputs = torch.tensor(input_ids)\n",
        "test_labels = torch.tensor(labels)\n",
        "test_masks = torch.tensor(attention_masks)\n",
        "\n",
        "print(test_inputs[0])\n",
        "print(test_labels[0])\n",
        "print(test_masks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I92Ao3SzAFCc",
        "outputId": "6acd0bda-9c27-47c5-a53f-adc400c74928"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   101,   8928,  47181,  21386,   8900, 118649, 118617,   9311,  30858,\n",
            "         22458,   9516,   9547,  46520,  12945,  71439,  10892,   9604,  46766,\n",
            "         14153,   9414, 103088,   9770,  53635,   9689,  11664,   9647, 119081,\n",
            "         48345,    119,    100,    122,  10954,    125,  21789,  38851,  19105,\n",
            "         10530,   9144,  90387,   9485, 101440,  10530,   9365, 118824, 119436,\n",
            "         85634,    100,    119,   9604,  44130,   9144,   9638,   9297,  17730,\n",
            "         14523,  74322,  10622,  19905,  12424,   9764,  27355,  18471,  17022,\n",
            "          9761,  33975,   8885,  16323, 108436,  16139,  11664,    100,    119,\n",
            "         21890,   9604,  44130,   8893, 118642,  18108,   9130,  68833,   9356,\n",
            "         14867,    100,  20729,  80956,   9547,  46520,  12945,  71439,  10739,\n",
            "          9949,  25486,  17022,   9641,  54305,  30050,  45021,  11664,    100,\n",
            "           119,   9596, 118728,   9952,  14867,   9604,  44130,   9764,  50248,\n",
            "          9460,  10954,  41886,   9366,  11102,  10739,  34079,   9547,  46520,\n",
            "         11513,   9954,   9405,  58762,  11513,   9282,  69164,   9358,  11903,\n",
            "         14867,   8908])\n",
            "tensor(1)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 배치 사이즈\n",
        "batch_size = 32\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "VbsUFdLWAFbF"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 생성\n"
      ],
      "metadata": {
        "id": "btUWJfJxAZiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류를 위한 BERT 모델 생성\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977,
          "referenced_widgets": [
            "9f65127b129b41c3adc7819827b30b2b",
            "2f0cb17fcabc414086ad0bef56cc792c",
            "37a8b48d5f8c4ceebd36c9d69ac715b1",
            "e6bd25a8be6f4df7a341df30ff4c8547",
            "d0ab8dd6e2214af0a49c75eb547b55da",
            "a8a2028629ed4832a0f96c5aaf462064",
            "643473197fdb4960b889cc424925a556",
            "74d3c1cd64f849d9aa6e8fb1d5255343",
            "1996b093b79543f390186182301195cc",
            "684b555f4be44308b12722d2e28cd0df",
            "ba370b5accdb411a818025aab8001fc5"
          ]
        },
        "id": "upJQVSNLAFzD",
        "outputId": "8840d9c6-3865-483d-a132-e25deb6fee19"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f65127b129b41c3adc7819827b30b2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # 학습률\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
        "                )\n",
        "\n",
        "# 에폭수\n",
        "epochs = 4\n",
        "\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpuJo9y4AGS-",
        "outputId": "d0323479-05e7-4bd3-9d3e-9aa28cae9085"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습"
      ],
      "metadata": {
        "id": "uqQZUpn_Amcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도 계산 함수\n",
        "def flat_accuracy(preds, labels):\n",
        "\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "YGp6SKdmAmZI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시간 표시 함수\n",
        "def format_time(elapsed):\n",
        "\n",
        "    # 반올림\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # hh:mm:ss으로 형태 변경\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "cN1-V_OGAmWu"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 재현을 위해 랜덤시드 고정\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 그래디언트 초기화\n",
        "model.zero_grad()\n",
        "\n",
        "# 에폭만큼 반복\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # 시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 로스 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    # 훈련모드로 변경\n",
        "    model.train()\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(DEVICE) for t in batch)\n",
        "\n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "\n",
        "        # 로스 구함\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # 총 로스 계산\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward 수행으로 그래디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 스케줄러로 학습률 감소\n",
        "        scheduler.step()\n",
        "\n",
        "        # 그래디언트 초기화\n",
        "        model.zero_grad()\n",
        "\n",
        "    # 평균 로스 계산\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    #시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 변수 초기화\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for batch in validation_dataloader:\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(DEVICE) for t in batch)\n",
        "\n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # 그래디언트 계산 안함\n",
        "        with torch.no_grad():\n",
        "            # Forward 수행\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # 출력 로짓 구함\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # CPU로 데이터 이동\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "SEICYKrSAmUI",
        "outputId": "95183adb-bdec-4263-87aa-fcf2278915a9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  9,048.    Elapsed: 0:05:42.\n",
            "  Batch 1,000  of  9,048.    Elapsed: 0:11:25.\n",
            "  Batch 1,500  of  9,048.    Elapsed: 0:17:08.\n",
            "  Batch 2,000  of  9,048.    Elapsed: 0:22:51.\n",
            "  Batch 2,500  of  9,048.    Elapsed: 0:28:34.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-93108fd4e509>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Backward 수행으로 그래디언트 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# 그래디언트 클리핑\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "평가"
      ],
      "metadata": {
        "id": "fISwajZ1AmRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        "\n",
        "# 평가모드로 변경\n",
        "model.eval()\n",
        "\n",
        "# 변수 초기화\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    # 경과 정보 표시\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    # 배치를 GPU에 넣음\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    # 배치에서 데이터 추출\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():\n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    # 출력 로짓 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "metadata": {
        "id": "gDNFp79pAmOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "새로운 문장 평가"
      ],
      "metadata": {
        "id": "_06XaE2pAmLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 데이터 변환\n",
        "def convert_input_data(sentences):\n",
        "\n",
        "    # BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "    # 입력 토큰의 최대 시퀀스 길이\n",
        "    MAX_LEN = 128\n",
        "\n",
        "    # 토큰을 숫자 인덱스로 변환\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    # 어텐션 마스크 초기화\n",
        "    attention_masks = []\n",
        "\n",
        "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "\n",
        "    # 데이터를 파이토치의 텐서로 변환\n",
        "    inputs = torch.tensor(input_ids)\n",
        "    masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return inputs, masks"
      ],
      "metadata": {
        "id": "rqvKv52nAmCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 테스트\n",
        "def test_sentences(sentences):\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 문장을 입력 데이터로 변환\n",
        "    inputs, masks = convert_input_data(sentences)\n",
        "\n",
        "    # 데이터를 GPU에 넣음\n",
        "    b_input_ids = inputs.to(device)\n",
        "    b_input_mask = masks.to(device)\n",
        "\n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():\n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    # 출력 로짓 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "\n",
        "    return logits"
      ],
      "metadata": {
        "id": "X34EOMnlAl1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = test_sentences(['---문장---'])\n",
        "\n",
        "print(logits)\n",
        "print(np.argmax(logits))"
      ],
      "metadata": {
        "id": "uhNTA3r3BArI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}